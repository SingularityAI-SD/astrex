{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import cifar10\n",
    "# load dataset\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: X=(50000, 32, 32, 3), y=(50000, 1)\n",
      "Test: X=(10000, 32, 32, 3), y=(10000, 1)\n"
     ]
    }
   ],
   "source": [
    "# summarize loaded dataset\n",
    "print('Train: X=%s, y=%s' % (X_train.shape, y_train.shape))\n",
    "print('Test: X=%s, y=%s' % (X_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers,models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 9, 9, 4, 1], dtype=uint8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = y_train.reshape(-1,)\n",
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\"airplane\",\"automobile\",\"bird\",\"cat\",\"deer\",\"dog\",\"frog\",\"horse\",\"ship\",\"truck\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sample(X, y, index):\n",
    "    plt.figure(figsize = (15,2))\n",
    "    plt.imshow(X[index])\n",
    "    plt.xlabel(classes[y[index]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_sample(X_train, y_train, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the images to a number from 0 to 1. Image has 3 channels (R,G,B) and \n",
    "# each value in the channel can range from 0 to 255. Hence to normalize in 0-->1 range, we need to divide it by 255\n",
    "\n",
    "X_train = X_train/255\n",
    "X_test = X_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-31 19:07:38.877257: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 26s 17ms/step - loss: 1.8142 - accuracy: 0.3532\n",
      "Epoch 2/5\n",
      "1563/1563 [==============================] - 26s 17ms/step - loss: 1.6251 - accuracy: 0.4260\n",
      "Epoch 3/5\n",
      "1563/1563 [==============================] - 26s 17ms/step - loss: 1.5435 - accuracy: 0.4583\n",
      "Epoch 4/5\n",
      "1563/1563 [==============================] - 27s 17ms/step - loss: 1.4812 - accuracy: 0.4785\n",
      "Epoch 5/5\n",
      "1563/1563 [==============================] - 26s 17ms/step - loss: 1.4338 - accuracy: 0.4959\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1551f3fd0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build simple artificial neural network for image classification\n",
    "ann = models.Sequential([\n",
    "        layers.Flatten(input_shape=(32,32,3)),\n",
    "        layers.Dense(3000, activation='relu'),\n",
    "        layers.Dense(1000, activation='relu'),\n",
    "        layers.Dense(10, activation='sigmoid') # 10 categories dataset    \n",
    "    ])\n",
    "\n",
    "ann.compile(optimizer='SGD',\n",
    "              loss='sparse_categorical_crossentropy', # for number classification use this loss\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "              # for one hot encoded classification use this categorical_crossentropy\n",
    "\n",
    "ann.fit(X_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 7ms/step\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.60      0.56      1000\n",
      "           1       0.66      0.58      0.62      1000\n",
      "           2       0.32      0.39      0.35      1000\n",
      "           3       0.39      0.24      0.30      1000\n",
      "           4       0.30      0.65      0.40      1000\n",
      "           5       0.46      0.31      0.37      1000\n",
      "           6       0.49      0.56      0.52      1000\n",
      "           7       0.69      0.34      0.46      1000\n",
      "           8       0.64      0.58      0.61      1000\n",
      "           9       0.62      0.47      0.53      1000\n",
      "\n",
      "    accuracy                           0.47     10000\n",
      "   macro avg       0.51      0.47      0.47     10000\n",
      "weighted avg       0.51      0.47      0.47     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix , classification_report\n",
    "import numpy as np\n",
    "y_pred = ann.predict(X_test)\n",
    "y_pred_classes = [np.argmax(element) for element in y_pred]\n",
    "\n",
    "print(\"Classification Report: \\n\", classification_report(y_test, y_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imporove performance of model using CNN\n",
    "# Now let us build a convolutional neural network to train our images\n",
    "\n",
    "cnn = models.Sequential([\n",
    "\n",
    "    # cnn\n",
    "    # convolutional neural network is for detecting the features of the image\n",
    "    layers.Conv2D(filters=32, kernel_size=(3, 3),#filtersize\n",
    "    activation='relu', input_shape=(32, 32, 3)),\n",
    "    layers.MaxPooling2D((2, 2)), #purpose of pooling layer is to progressively \n",
    "    #reduce the spatial size of the input image, so that number of computations in the network are reduced.\n",
    "    \n",
    "    layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    # dense\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# softmax vs sigmoid \n",
    "\n",
    "'''\n",
    "Sigmoid:\n",
    "lets say probability of 2 class\n",
    "1: .90\n",
    "2: .85\n",
    "\n",
    "Softmax: Normalizes\n",
    "1: .90\n",
    "2: .85\n",
    "\n",
    "1: .90/(.90+.85)\n",
    "2: .85/(.90+.85)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 1.4895 - accuracy: 0.4664\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 12s 7ms/step - loss: 1.1386 - accuracy: 0.6010\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 12s 7ms/step - loss: 1.0109 - accuracy: 0.6498\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.9241 - accuracy: 0.6801\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.8638 - accuracy: 0.7006\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.8154 - accuracy: 0.7182\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.7666 - accuracy: 0.7344\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.7254 - accuracy: 0.7504\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.6887 - accuracy: 0.7613\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.6522 - accuracy: 0.7751\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x137d05f10>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.fit(X_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.62      0.69      1000\n",
      "           1       0.84      0.81      0.82      1000\n",
      "           2       0.56      0.59      0.58      1000\n",
      "           3       0.50      0.55      0.52      1000\n",
      "           4       0.64      0.62      0.63      1000\n",
      "           5       0.68      0.52      0.59      1000\n",
      "           6       0.70      0.82      0.76      1000\n",
      "           7       0.70      0.79      0.74      1000\n",
      "           8       0.78      0.83      0.81      1000\n",
      "           9       0.78      0.80      0.79      1000\n",
      "\n",
      "    accuracy                           0.69     10000\n",
      "   macro avg       0.70      0.69      0.69     10000\n",
      "weighted avg       0.70      0.69      0.69     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = cnn.predict(X_test)\n",
    "y_pred_classes = [np.argmax(element) for element in y_pred]\n",
    "\n",
    "print(\"Classification Report: \\n\", classification_report(y_test, y_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.9203 - accuracy: 0.6946\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9202882051467896, 0.694599986076355]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = cnn.predict(X_test)\n",
    "y_pred[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 8, 8, 0, 6], dtype=uint8)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = y_test.reshape(-1,)\n",
    "y_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2.5724526e-04, 4.8324079e-03, 8.1421237e-04, 9.2053133e-01,\n",
       "       9.0953436e-05, 4.8115719e-03, 1.1231679e-02, 1.3696235e-05,\n",
       "       5.7378456e-02, 3.8356986e-05], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = cnn.predict(X_test)\n",
    "y_pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_classes = [np.argmax(element) for element in y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cat'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes[y_classes[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9 (v3.9.9:ccb0e6a345, Nov 15 2021, 13:06:05) \n[Clang 13.0.0 (clang-1300.0.29.3)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
